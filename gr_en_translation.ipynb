{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b69e67f-ebc6-4a2e-8e7b-c9b91803c8b7",
   "metadata": {},
   "source": [
    "### NLP PRoject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad3b9138-124b-44ad-bd05-eae59562583f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76aaf8c4-1f73-4df0-97a7-2042a9e7bf4a",
   "metadata": {},
   "source": [
    "!cat *.compare > NLP-Translation-GR-EN-Data.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3ef442f-a2bf-4eac-a121-feed1f297b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'NLP-Translation-GR-EN-Data.txt'  \n",
    "greek_csv = 'Greek-Text.csv'  \n",
    "english_csv = 'English-Text.csv'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abb9d6a2-4627-44b0-a2c8-b9a29388d9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files have been written successfully.\n"
     ]
    }
   ],
   "source": [
    "# Open the input file for reading\n",
    "with open(input_file, 'r', encoding='utf-8') as infile:\n",
    "    lines = infile.readlines()\n",
    "\n",
    "# Open the output CSV files for writing\n",
    "with open(greek_csv, 'w', encoding='utf-8', newline='') as greek_out, \\\n",
    "     open(english_csv, 'w', encoding='utf-8', newline='') as english_out:\n",
    "\n",
    "    # Create CSV writers\n",
    "    greek_writer = csv.writer(greek_out)\n",
    "    english_writer = csv.writer(english_out)\n",
    "\n",
    "    # Write headers to the CSV files\n",
    "    greek_writer.writerow(['Sentence', 'Line'])\n",
    "    english_writer.writerow(['Sentence', 'Line'])\n",
    "\n",
    "    # Process the input file lines in the correct pattern\n",
    "    greek_line_number = 1\n",
    "    english_line_number_1 = 2\n",
    "    english_line_number_2 = 3\n",
    "    \n",
    "    # Iterate over the lines and select the Greek and English lines\n",
    "    for i in range(0, len(lines), 8):\n",
    "\n",
    "        # Write Greek lines to Greek-Text CSV \n",
    "        greek_line = lines[i].strip()\n",
    "        if greek_line:\n",
    "            greek_writer.writerow([greek_line, greek_line_number])  # Write sentence and line number\n",
    "            greek_line_number += 4  # Move to the next Greek line number (1, 5, 9, 13, ...)\n",
    "\n",
    "        # Write English lines to English-Text CSV (2-3, 6-7, 10-11, ...)\n",
    "        if i + 1 < len(lines):  # Ensure the line exists before writing\n",
    "            english_line1 = lines[i + 1].strip()\n",
    "            if english_line1:\n",
    "                english_writer.writerow([english_line1, english_line_number_1])  # Write English sentence and line number\n",
    "                english_line_number_1 += 4  # Move to the next English line number (2, 6, 10, 14, ...)\n",
    "\n",
    "        if i + 2 < len(lines):  # Ensure the line exists before writing\n",
    "            english_line2 = lines[i + 2].strip()\n",
    "            if english_line2:\n",
    "                english_writer.writerow([english_line2, english_line_number_2])  # Write English sentence and line number\n",
    "                english_line_number_2 += 4  # Move to the next English line number (3, 7, 11, 15, ...)\n",
    "\n",
    "print(\"CSV files have been written successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8a9fd32-8f26-4080-af37-1be3ba614abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linguistic phenomena CSV file has been written successfully: GR-Linguistics.csv\n"
     ]
    }
   ],
   "source": [
    "# Define file paths\n",
    "input_file = 'Greek-Text.csv'  # Input CSV file containing Greek sentences with line numbers\n",
    "output_csv = 'GR-Linguistics.csv'  # Output CSV file for linguistic phenomena\n",
    "\n",
    "# Define keywords for each linguistic phenomenon\n",
    "# Negation keywords (more common negation terms in Greek)\n",
    "negation_keywords = [\n",
    "    'Δεν', 'Μη', 'Ούτε', 'Πουθενά', 'Ποτέ', 'Καθόλου', 'Κανένας', 'Καμία', 'Κανένα', 'Τίποτα',\n",
    "    'ούτε καν', 'μηδέν', 'απαγορεύεται', 'όχι', 'μηδέν'\n",
    "]\n",
    "\n",
    "# Coordination keywords (common words used for coordination in Greek)\n",
    "coordination_keywords = [\n",
    "    'ή', 'και', 'ή...ή', 'ούτε...ούτε', 'άρα'\n",
    "]\n",
    "\n",
    "# Subordination keywords (words used to introduce subordinate clauses)\n",
    "subordination_keywords = [\n",
    "    'αν', 'σαν', 'πως', 'ότι', 'όπως', 'πριν', 'για να', 'όταν', 'εφόσον', 'αν και', 'αφού', 'διότι', 'γιατί', 'επειδή'\n",
    "]\n",
    "\n",
    "\n",
    "# Open the input Greek text file (assuming it's in CSV format)\n",
    "with open(input_file, 'r', encoding='utf-8') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    next(reader)  # Skip the header\n",
    "\n",
    "    # Open the output CSV file for writing\n",
    "    with open(output_csv, 'w', encoding='utf-8', newline='') as outfile:\n",
    "        writer = csv.writer(outfile)\n",
    "        writer.writerow(['Sentence', 'Line', 'Linguistic Phenomenon'])\n",
    "\n",
    "        # Track if we write any data to the output file\n",
    "        rows_written = 0\n",
    "\n",
    "        # Iterate over the rows of the Greek text CSV\n",
    "        for row in reader:\n",
    "            greek_sentence = row[0].strip()  # Extract the Greek sentence\n",
    "            try:\n",
    "                # Try to convert the second column to an integer for line number\n",
    "                line_number = int(row[1])\n",
    "            except ValueError:\n",
    "                # If the line number is not a valid integer, skip this row\n",
    "                print(f\"Warning: Skipping row due to invalid line number format: {row}\")\n",
    "                continue\n",
    "\n",
    "            # Check for each linguistic phenomenon using regex\n",
    "            if any(re.search(rf'\\b{keyword}\\b', greek_sentence) for keyword in negation_keywords):\n",
    "                writer.writerow([greek_sentence, line_number, 'Negation'])\n",
    "                rows_written += 1\n",
    "            elif any(re.search(rf'\\b{keyword}\\b', greek_sentence) for keyword in coordination_keywords):\n",
    "                writer.writerow([greek_sentence, line_number, 'Coordination'])\n",
    "                rows_written += 1\n",
    "            elif any(re.search(rf'\\b{keyword}\\b', greek_sentence) for keyword in subordination_keywords):\n",
    "                writer.writerow([greek_sentence, line_number, 'Subordination'])\n",
    "                rows_written += 1\n",
    "\n",
    "        # Check if any rows were written and provide feedback\n",
    "        if rows_written > 0:\n",
    "            print(f\"Linguistic phenomena CSV file has been written successfully: {output_csv}\")\n",
    "        else:\n",
    "            print(\"No matching linguistic phenomena were found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18f80cb9-1e2b-4d25-91c3-493477df97c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sort GR-Linguistics.csv | uniq > GR-Linguistics-uid.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b723d876-9ada-4d59-92f6-5c8771756b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1071\n",
      "952\n",
      "1347\n"
     ]
    }
   ],
   "source": [
    "!grep -c \"Negation\" GR-Linguistics-uid.csv\n",
    "!grep -c \"Coordination\" GR-Linguistics-uid.csv\n",
    "!grep -c \"Subordination\" GR-Linguistics-uid.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1539147-bbad-4520-bf21-b1886efbee88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping row due to invalid line number: Line\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Read the linguistic CSV file and write sentences to source.txt\n",
    "with open('GR-Linguistics-uid.csv', newline='', encoding='utf-8') as linguistics_file:\n",
    "    linguistics_reader = csv.reader(linguistics_file)\n",
    "    \n",
    "    # Skip the header row\n",
    "    next(linguistics_reader)\n",
    "    \n",
    "    # Open the source.txt file to write the linguistic sentences\n",
    "    with open('source.txt', 'w', encoding='utf-8') as source_file:\n",
    "        for row in linguistics_reader:\n",
    "            sentence = row[0]  # First column contains the linguistic sentence\n",
    "            source_file.write(sentence + \"\\n\")  # Write each sentence to source.txt one below the other\n",
    "\n",
    "# Read the English CSV file into a list for easier access\n",
    "with open('English-Text.csv', newline='', encoding='utf-8') as english_file:\n",
    "    english_reader = csv.reader(english_file)\n",
    "    english_sentences = list(english_reader)  # Convert to list to easily access by index\n",
    "\n",
    "# Open the target.txt file to write the English sentences based on linguistic row numbers\n",
    "with open('target.txt', 'w', encoding='utf-8') as target_file:\n",
    "    # Rewind the linguistics file to process again, this time for line numbers\n",
    "    with open('GR-Linguistics-uid.csv', newline='', encoding='utf-8') as linguistics_file:\n",
    "        linguistics_reader = csv.reader(linguistics_file)\n",
    "        \n",
    "        # Skip the header row again\n",
    "        next(linguistics_reader)\n",
    "        \n",
    "        for row in linguistics_reader:\n",
    "            try:\n",
    "                line_number = int(row[1])  # Second column contains the line number for English sentences\n",
    "                \n",
    "                # Find the row in the English file where the second column equals line_number + 1\n",
    "                found_row = None\n",
    "                for i, eng_row in enumerate(english_sentences):\n",
    "                    if str(line_number + 1) == eng_row[1]:  # Matching line_number + 1 in English CSV\n",
    "                        found_row = i\n",
    "                        break\n",
    "                \n",
    "                if found_row is not None:\n",
    "                    # Write the found row and the next row (found_row + 1)\n",
    "                    if found_row + 1 < len(english_sentences):  # Ensure there's a next row\n",
    "                        target_file.write(english_sentences[found_row][0] + \"\\n\")  # Sentence from found_row\n",
    "                       # target_file.write(english_sentences[found_row + 1][0] + \"\\n\")  # Sentence from next row\n",
    "                    else:\n",
    "                        print(f\"Skipping line {line_number + 1} because there is no next row in English.\")\n",
    "                else:\n",
    "                    print(f\"Line number {line_number + 1} not found in English-Text.csv.\")\n",
    "            except ValueError:\n",
    "                print(f\"Skipping row due to invalid line number: {row[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4864b96-df6e-496e-9410-9b9dac4bb753",
   "metadata": {},
   "outputs": [],
   "source": [
    "!awk '!seen[$0]++' source.txt > combined.tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54177a93-59f2-4a39-8f02-16f711f25082",
   "metadata": {},
   "outputs": [],
   "source": [
    "!awk '!seen[$0]++' target.txt > neo.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c7db790-252c-42e1-a7c4-5bc2df5ccb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3371 GR-Linguistics-uid.csv\n"
     ]
    }
   ],
   "source": [
    "!wc -l GR-Linguistics-uid.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bab3ee13-4746-4b3b-b973-f19f815248d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wc: Source-Text-GR.txt: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!wc -l Source-Text-GR.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ee379cb-cbb4-45d4-b7a0-4c7831ab0d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2067 combined.tx\n"
     ]
    }
   ],
   "source": [
    "!wc -l combined.tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6611cfe4-b379-421a-a6f7-d2a06a40c96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:Sentence\n"
     ]
    }
   ],
   "source": [
    "!grep -in \"sentence\" source.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36e6ae9b-b7aa-43c8-a4e6-20540ae5aeaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Even traditionally, though, not all Sámi have been involved in big scale reindeer husbandry, but lived from fishing, hunting and similar, having reindeer mostly as draft animals.\n"
     ]
    }
   ],
   "source": [
    "!sed -n '23p' target.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ecf5a79b-2a17-437c-bf74-15422b3d6ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ακολούθως, στα καλύτερα από αυτά τα καταλύματα μπορεί να βρει κανείς τα πιο πολυτελή είδη κρεβατιού, ίσως ένα χειροποίητο πάπλωμα ή ένα κρεβάτι αντίκα.\n"
     ]
    }
   ],
   "source": [
    "!sed -n '23p' source.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f556782a-847e-4f64-98d0-ddb03c59f9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: cannot stat 'combined.txt': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!cp combined.txt gr-input.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33647b23-f369-4b25-aece-9d41b007c9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp neo.txt en-human-translation.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ba848cb-9378-433e-8c98-41077428a370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Check the output file: OUTPUT.txt\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def process_csv(input_csv1, input_csv2, output_txt):\n",
    "    try:\n",
    "        # Read the second CSV into a dictionary for faster lookup\n",
    "        csv2_data = {}\n",
    "        with open(input_csv2, mode='r') as file2:\n",
    "            reader2 = csv.reader(file2)\n",
    "            for row in reader2:\n",
    "                if len(row) >= 2 and row[1].isdigit():  # Ensure the second column is numeric\n",
    "                    csv2_data[int(row[1])] = row[0]  # {second_column: first_column}\n",
    "\n",
    "        # Open the first CSV and output text file\n",
    "        with open(input_csv1, mode='r') as file1, open(output_txt, mode='w') as output_file:\n",
    "            reader1 = csv.reader(file1)\n",
    "            for row in reader1:\n",
    "                if len(row) >= 2 and row[1].isdigit():  # Ensure the second column is numeric\n",
    "                    value_to_find = int(row[1]) + 1  # Second column value + 1\n",
    "                    if value_to_find in csv2_data:\n",
    "                        output_file.write(csv2_data[value_to_find] + '\\n')\n",
    "\n",
    "        print(f\"Processing complete. Check the output file: {output_txt}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "input_csv1 = \"GR-Linguistics-uid.csv\"  # Replace with the first CSV filename\n",
    "input_csv2 = \"English-Text.csv\"  # Replace with the second CSV filename\n",
    "output_txt = \"OUTPUT.txt\"  # Replace with the desired output text filename\n",
    "\n",
    "process_csv(input_csv1, input_csv2, output_txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26cf5b3f-d0e8-4f52-9c6d-ad5969676274",
   "metadata": {},
   "outputs": [],
   "source": [
    "!awk '!seen[$0]++' OUTPUT.txt > deduplicated_output.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88192d8b-373d-4b2a-b388-a1d966d03b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Check the output file: OUTPUT.txt\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def process_csv(input_csv1, input_csv2, gr_input_txt, output_txt):\n",
    "    try:\n",
    "        # Load sentences from gr_input.txt into a set\n",
    "        with open(gr_input_txt, mode='r') as gr_file:\n",
    "            gr_sentences = set(line.strip() for line in gr_file if line.strip())\n",
    "\n",
    "        # Read the second CSV into a dictionary for faster lookup\n",
    "        csv2_data = {}\n",
    "        with open(input_csv2, mode='r') as file2:\n",
    "            reader2 = csv.reader(file2)\n",
    "            for row in reader2:\n",
    "                if len(row) >= 2 and row[1].isdigit():  # Ensure the second column is numeric\n",
    "                    csv2_data[int(row[1])] = row[0]  # {second_column: first_column}\n",
    "\n",
    "        # Open the first CSV and output text file\n",
    "        with open(input_csv1, mode='r') as file1, open(output_txt, mode='w') as output_file:\n",
    "            reader1 = csv.reader(file1)\n",
    "            for row in reader1:\n",
    "                if len(row) >= 2 and row[0] in gr_sentences:  # Match sentence in the first column\n",
    "                    if row[1].isdigit():  # Ensure the second column is numeric\n",
    "                        value_to_find = int(row[1]) + 1  # Second column value + 1\n",
    "                        if value_to_find in csv2_data:\n",
    "                            output_file.write(csv2_data[value_to_find] + '\\n')  # Write matching sentence\n",
    "\n",
    "        print(f\"Processing complete. Check the output file: {output_txt}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# File paths\n",
    "input_csv1 = \"GR-Linguistics-uid.csv\"  # Replace with the first CSV filename\n",
    "input_csv2 = \"English-Text.csv\"        # Replace with the second CSV filename\n",
    "gr_input_txt = \"gr-input.txt\"          # Replace with the Greek input text filename\n",
    "output_txt = \"OUTPUT.txt\"              # Replace with the desired output text filename\n",
    "\n",
    "process_csv(input_csv1, input_csv2, gr_input_txt, output_txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4410714f-1412-49e1-99f4-456053ae5c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!awk '!seen[$0]++' OUTPUT.txt > deduplicated_output.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0995518-a95a-4c0a-a560-5261ae5f5661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Check the output file: OUTPUT.txt\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def process_csv(input_csv1, input_csv2, gr_input_txt, output_txt):\n",
    "    try:\n",
    "        # Load sentences from gr_input.txt into a set\n",
    "        with open(gr_input_txt, mode='r') as gr_file:\n",
    "            gr_sentences = set(line.strip() for line in gr_file if line.strip())\n",
    "\n",
    "        # Read the second CSV into a dictionary for faster lookup\n",
    "        csv2_data = {}\n",
    "        with open(input_csv2, mode='r') as file2:\n",
    "            reader2 = csv.reader(file2)\n",
    "            for row in reader2:\n",
    "                if len(row) >= 2 and row[1].isdigit():  # Ensure the second column is numeric\n",
    "                    csv2_data[int(row[1])] = row[0]  # {second_column: first_column}\n",
    "\n",
    "        # Open the first CSV and output text file\n",
    "        with open(input_csv1, mode='r') as file1, open(output_txt, mode='w') as output_file:\n",
    "            reader1 = csv.reader(file1)\n",
    "            for row in reader1:\n",
    "                if len(row) >= 2 and row[0] in gr_sentences:  # Match sentence in the first column\n",
    "                    if row[1].isdigit():  # Ensure the second column is numeric\n",
    "                        value_to_find = int(row[1]) + 1  # Second column value + 1\n",
    "                        if value_to_find in csv2_data:\n",
    "                            output_file.write(csv2_data[value_to_find] + '\\n')  # Write matching sentence\n",
    "\n",
    "        print(f\"Processing complete. Check the output file: {output_txt}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# File paths\n",
    "input_csv1 = \"GR-Linguistics-uid.csv\"  # Replace with the first CSV filename\n",
    "input_csv2 = \"English-Text.csv\"        # Replace with the second CSV filename\n",
    "gr_input_txt = \"gr-input.txt\"          # Replace with the Greek input text filename\n",
    "output_txt = \"OUTPUT.txt\"              # Replace with the desired output text filename\n",
    "\n",
    "process_csv(input_csv1, input_csv2, gr_input_txt, output_txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1f70c14-1dfe-43b6-be54-d2b2da443791",
   "metadata": {},
   "outputs": [],
   "source": [
    "!awk '!seen[$0]++' OUTPUT.txt > deduplicated_output.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8512baa4-042a-455a-a1cb-9861713b284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!awk '!seen[$0]++' GR-Linguistics-uid.csv > deduplicated_output.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "535c13a8-0ba9-4ace-8dc2-373cf6b01ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content of the first column copied to elala.txt\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def copy_first_column_to_txt(input_csv, output_txt):\n",
    "    try:\n",
    "        with open(input_csv, mode='r', encoding='utf-8') as csv_file, open(output_txt, mode='w', encoding='utf-8') as txt_file:\n",
    "            reader = csv.reader(csv_file)\n",
    "            for row in reader:\n",
    "                if len(row) > 0:  # Ensure there's at least one column\n",
    "                    txt_file.write(row[0] + '\\n')  # Write the first column to the text file\n",
    "        print(f\"Content of the first column copied to {output_txt}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# File paths\n",
    "input_csv = \"GR-Linguistics-uid.csv\"  # Replace with your CSV filename\n",
    "output_txt = \"elala.txt\"  # Replace with your desired text filename\n",
    "\n",
    "copy_first_column_to_txt(input_csv, output_txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e8484eda-d4a5-4cfa-8b2c-c2ac1a0431e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!awk '!seen[$0]++' elala.txt > deduplicated_output.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a35ef6fd-a9ff-4fd1-a31d-a28b3e98bab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Unique sentences written to output.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def process_csv(input_csv, output_csv):\n",
    "    try:\n",
    "        unique_sentences = {}\n",
    "        \n",
    "        # Read the input CSV\n",
    "        with open(input_csv, mode='r') as infile:\n",
    "            reader = csv.reader(infile)\n",
    "            header = next(reader, None)  # Capture the header, if present\n",
    "            \n",
    "            for row in reader:\n",
    "                if len(row) >= 2:  # Ensure there are at least two columns\n",
    "                    sentence = row[0].strip()\n",
    "                    value = row[1].strip()\n",
    "                    \n",
    "                    # Keep only one instance of each sentence\n",
    "                    if sentence not in unique_sentences:\n",
    "                        unique_sentences[sentence] = value\n",
    "        \n",
    "        # Write to the output CSV\n",
    "        with open(output_csv, mode='w', newline='') as outfile:\n",
    "            writer = csv.writer(outfile)\n",
    "            \n",
    "            # Write the header, if the input CSV had one\n",
    "            if header:\n",
    "                writer.writerow(header)\n",
    "            \n",
    "            for sentence, value in unique_sentences.items():\n",
    "                writer.writerow([sentence, value])\n",
    "        \n",
    "        print(f\"Processing complete. Unique sentences written to {output_csv}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# File paths\n",
    "input_csv = \"GR-Linguistics-uid.csv\"    # Replace with your input CSV filename\n",
    "output_csv = \"output.csv\"  # Replace with your desired output CSV filename\n",
    "\n",
    "process_csv(input_csv, output_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cdd752b6-3d6d-413b-a264-1d14b6b37300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Check the output file: TRANS.txt\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def find_and_write(input_csv, lookup_csv, output_txt):\n",
    "    try:\n",
    "        # Read the lookup CSV into a dictionary for faster access\n",
    "        lookup_data = {}\n",
    "        with open(lookup_csv, mode='r') as lookup_file:\n",
    "            reader = csv.reader(lookup_file)\n",
    "            for row in reader:\n",
    "                if len(row) >= 2 and row[1].isdigit():  # Ensure the second column is numeric\n",
    "                    lookup_data[int(row[1])] = row[0]  # {second_column: first_column}\n",
    "\n",
    "        # Open the input CSV and output text file\n",
    "        with open(input_csv, mode='r') as input_file, open(output_txt, mode='w') as output_file:\n",
    "            reader = csv.reader(input_file)\n",
    "            for row in reader:\n",
    "                if len(row) >= 2 and row[1].isdigit():  # Ensure the second column is numeric\n",
    "                    value_to_find = int(row[1]) + 1  # Second column value + 1\n",
    "                    if value_to_find in lookup_data:\n",
    "                        output_file.write(lookup_data[value_to_find] + '\\n')  # Write matching content to file\n",
    "\n",
    "        print(f\"Processing complete. Check the output file: {output_txt}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# File paths\n",
    "input_csv = \"output.csv\"        # Replace with the input CSV filename\n",
    "lookup_csv = \"English-Text.csv\"        # Replace with the lookup CSV filename\n",
    "output_txt = \"TRANS.txt\"       # Replace with the desired text output filename\n",
    "\n",
    "find_and_write(input_csv, lookup_csv, output_txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e1238810-2d7c-40c3-aeb8-d567f4d11ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During the 18th century Cambodia found itself squeezed between two powerful neighbors, Thailand and Vietnam.\n"
     ]
    }
   ],
   "source": [
    "!sed -n '999p' TRANS.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1efc6f9-2146-40b7-9547-6aa87dff0223",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
